%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{catchfilebetweentags} %% For importing code snippets
\usepackage{lineno} %% For line numbers on code snippets
\usepackage{pgfplots}
\usepackage{multicol}
\usepackage{fancyvrb}
\usepackage{wrapfig}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Agda special Characters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb}
\usepackage{turnstile}
\usepackage{bbm}
\usepackage[greek, english]{babel}
\usepackage{MnSymbol}
\usepackage{stmaryrd}
\usepackage{csquotes}
\newcommand\doubleplus{+\kern-1.3ex+\kern0.8ex}
\newcommand\mdoubleplus{\ensuremath{\mathbin{+\mkern-8mu+}}}
\makeatletter
\newcommand\incircbin
{%
  \mathpalette\@incircbin
}
\newcommand\@incircbin[2]
{%
  \mathbin%
  {%
    \ooalign{\hidewidth$#1#2$\hidewidth\crcr$#1\bigcirc$}%
  }%
}
\newcommand{\oeq}{\ensuremath{\incircbin{=}}}
\makeatother
\makeatletter
\newcommand\insquarebin
{%
  \mathpalette\@insquarebin
}
\newcommand\@insquarebin[2]
{%
  \mathbin%
  {%
    \ooalign{\hidewidth$#1#2$\hidewidth\crcr$#1\bigbox$}%
  }%
}
\newcommand{\sqtri}{\ensuremath{\insquarebin{\triangle}}}
\makeatother
\usepackage{ucs}
\DeclareUnicodeCharacter{8759}{\ensuremath{\squaredots}}
\DeclareUnicodeCharacter{951}{\textgreek{\texteta}}
\DeclareUnicodeCharacter{737}{\ensuremath{^\text{l}}}
\DeclareUnicodeCharacter{691}{\ensuremath{^\text{r}}}
\DeclareUnicodeCharacter{7523}{\ensuremath{_\text{r}}}
\DeclareUnicodeCharacter{8343}{\ensuremath{_\text{l}}}
\DeclareUnicodeCharacter{8718}{\ensuremath{\blacksquare}}
\DeclareUnicodeCharacter{957}{\textgreek{\textnu}}
\DeclareUnicodeCharacter{961}{\textgreek{\textrho}}
\DeclareUnicodeCharacter{929}{\textgreek{\textRho}}
\DeclareUnicodeCharacter{954}{\textgreek{\textkappa}}
\DeclareUnicodeCharacter{10214}{\ensuremath{\lsem}}
\DeclareUnicodeCharacter{10215}{\ensuremath{\rsem}}
\DeclareUnicodeCharacter{8857}{\mdoubleplus}
\DeclareUnicodeCharacter{8860}{\oeq}
\DeclareUnicodeCharacter{9043}{\ensuremath{\sqtri}}
\DeclareUnicodeCharacter{928}{\textgreek{\textPi}}
\DeclareUnicodeCharacter{922}{\textgreek{\textKappa}}
\DeclareUnicodeCharacter{931}{\textgreek{\textSigma}}
\DeclareUnicodeCharacter{916}{\textgreek{\textDelta}}
\DeclareUnicodeCharacter{921}{\textgreek{\textIota}}
\DeclareUnicodeCharacter{8779}{\ensuremath{\backtriplesim}}
\DeclareUnicodeCharacter{8799}{\ensuremath{\stackrel{?}{=}}}
\DeclareUnicodeCharacter{10181}{\ensuremath{\lbag}}
\DeclareUnicodeCharacter{10182}{\ensuremath{\rbag}}
\DeclareUnicodeCharacter{8760}{\ensuremath{-}}
\usepackage[references]{agda}

\newcommand{\Nat}{\AgdaDatatype{ℕ}}
\newcommand{\Int}{\AgdaDatatype{ℤ}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\theoremstyle{remark}
\newtheorem{principle}{Principle}

\begin{document}

%% Title information
\title[Reading and Writing Arithmetic]{Reading and Writing Arithmetic: Automating Ring Equalities
  in Agda}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Donnacha Oisín Kidney}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended



%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  We present a new library which automates the construction of equivalence
  proofs between polynomials over commutative rings and semirings in the
  programming language Agda \cite{norell_dependently_2008}. It is significantly
  faster than Agda's existing solver. We use reflection to provide a simple
  interface to the solver, and demonstrate a novel use of the constructed
  relations: step-by-step solutions.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{proof automation, equivalence, proof by reflection, step-by-step solutions}


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.

\begin{teaserfigure}
  \centering
  \begin{subfigure}[b]{\textwidth}
    \centering
    \ExecuteMetaData[../Introduction.tex]{lemma}
    \label{ring-lemma}
  \end{subfigure}
  \begin{subfigure}[b]{.5\textwidth}
    \ExecuteMetaData[../Introduction.tex]{proof}
    \caption{A Tedious Proof}
    \label{ring-proof}
  \end{subfigure}%
  \begin{subfigure}[b]{.3\textwidth}
    \centering
    \ExecuteMetaData[../Introduction.tex]{solver}
    \caption{Our Solver}
    \label{the-solver}
  \end{subfigure}
  \caption{Comparison Between A Manual Proof and The Automated Solver}
  \label{comparison}
\end{teaserfigure}

\maketitle

\begin{figure}
  \ExecuteMetaData[../Introduction.tex]{old-solver}
  \caption{The Old Solver}
  \label{old-solver}
\end{figure}
\section{Introduction}
Doing mathematics in dependently-typed programming languages like Agda has a
reputation for being tedious. Even simple arithmetic identities like the one in
Fig.~\ref{comparison} require fussy proofs (Fig.~\ref{ring-proof}).

This need not be the case! With some carefully-designed tools, mathematics in
Agda can be easy, friendly, and fun. This work describes one such tool: an
Agda library which automates the construction of proofs like
Fig.~\ref{ring-proof}, making them as easy as Fig.~\ref{the-solver}.

While correctness is, of course, an essential feature of any library like ours,
it's not the whole story. For this work, we also felt that it was important to
achieve the following:
\begin{description}
  \item[Ease of Use] Proofs like the one in Fig.~\ref{ring-proof} aren't just
    boring: they're \emph{difficult}. The programmer needs to remember the
    particular syntax for each step (``is it \(\AgdaFunction{+-comm}\) or
    \(\AgdaFunction{+-commutative}\)?''), and often they have to put up with
    poor error messages.

    This difficulty comprises a large part of the motivation behind a solver
    like ours: by reducing the amount of uninteresting proof code a programmer
    needs to write, we hope to make larger formalisations of mathematics more
    achievable. It's absolutely \emph{vital}, then, that the solver is easy to
    use: if it's easier to prove something manually than it is to automate it,
    what was the point of the automation in the first place?

    We feel that we have improved on Agda's current solver
    \cite{danielsson_agda_2018} in this regard. While it can automate proofs
    like Fig.~\ref{ring-proof}, its interface (Fig.~\ref{old-solver}) is quite
    verbose, and it requires programmers to learn another syntax specific to the
    solver.

    Our solver strives to be as easy to use as possible: the high-level
    interface is simple (Fig.~\ref{the-solver}), we don't require anything
    of the user other than an implementation of one of the supported algebras,
    and effort is made to generate useful error messages.
  \item[Performance] Typechecking dependently-typed code is a costly task.
    Automated solvers like the one presented here can greatly exacerbate this
    cost: in our experience, it wasn't uncommon for Agda's current ring solver
    to spend upwards of 10 minutes proving a single identity.

    In practice, this means two things: firstly, large libraries for formalising
    mathematics (like \citet{meshveliani_docon-provable_2018}) can potentially
    take hours to typecheck (by which time the programmer has understandably
    begun to reconsider the whole notion of mathematics on a computer);
    secondly, certain identities can simply take too long to typecheck,
    effectively making them ``unprovable'' in Agda altogether!

    The kind of solver we provide here is based on Coq's
    \cite{the_coq_development_team_2018_1219885} \verb+ring+ tactic, described
    in \citet{gregoire_proving_2005}. While we were able to apply the same
    optimisations that were applied in that paper, we found that the most
    significant performance improvements came from a different, and somewhat
    surprising part of the program. In terms of both practical use and
    theoretical bounds, our solver is significantly faster than Agda's current
    solver.
  \item[Educational Features] Outside the rigorous world of dependently-typed
    languages, computer algebra systems (of one form or another) have had
    massive success among programmers and non-programmers alike. These days,
    many of these systems (like Wolfram|Alpha
    \cite{wolfram_research_inc._wolframalpha_2019}) provide educational
    features, which have proven invaluable to students learning mathematics.

    We will take just one of those features (``pedagogical'', or step-by-step
    solutions \cite{the_development_team_step-by-step_2009}), and re-implement
    it in Agda using our solver. In doing so, we will formalise the concept, and
    explore some of the theory behind it. 
\end{description}
\section{Overview of the Proof Technique}
\begin{figure}[b]
  \resizebox{\textwidth}{!}{\includegraphics[draft=false]{graphics/reflexive-process}}
  \vspace*{-50pt}
  \caption{The Reflexive Proof Process}
  \label{proof-process}
\end{figure}

There are a number of ways we can automate proofs in a dependently-typed
programming language, including Prolog-like proof search \cite{kokke_auto_2015},
Cooper's algorithm over Presburger arithmetic \cite{allais_deciding_2011}, etc.
Here, we will use a reflexive technique \cite{boutin_using_1997} in combination
with sparse Horner Normal Form. The high-level diagram of the proof strategy is
presented in Fig.~\ref{proof-process}.

The identity we'll be working with is the lemma in Fig.~\ref{comparison}: the
left and right hand side of the equivalence are at the bottom of the diagram. Our
objective is to link those two expressions up through repeated application of
the ring axioms. We do this by converting both expressions to a normal form
(seen at the top of the diagram), and then providing a proof that this
conversion is correct according to the ring axioms (the
\(\AgdaFunction{correct}\) function in the diagram). Finally, we link up all of
these proofs, and if the two normal forms are definitionally equal, the entire
thing will typecheck, and we will have proven the equivalence.
\subsection{The \(\AgdaDatatype{Expr}\) AST}
To get started, we'll first define an Abstract Syntax Tree (AST) to describe
expressions which use the ring operators.
\begin{center}
  \ExecuteMetaData[../ReflectionSection.tex]{expr-def}
\end{center}
Each of the ring operators has a corresponding constructor (\(x + y = x \;
\AgdaInductiveConstructor{⊕} \; y\), \(x^y = x \; \AgdaInductiveConstructor{⊗}
\; y\)), constants are constructed with \(\AgdaInductiveConstructor{K}\), and
variables are referred to by their de Bruijn index (so \(x\) becomes
\(\AgdaInductiveConstructor{I} \;  \AgdaNumber{0}\)). The ASTs for both
expressions we want to prove can be seen on either side of
Fig.~\ref{proof-process}.

From here, we can ``evaluate'' the AST in one of two ways: in a non-normalised
way (\(\AgdaFunction{⟦\_⟧}\)), or in a normalising way
(\(\AgdaFunction{⟦\_⇓⟧}\)). This means that the goal of the
\(\AgdaFunction{correct}\) function is to show equivalence between
\(\AgdaFunction{⟦\_⟧}\) and \(\AgdaFunction{⟦\_⇓⟧}\).
\subsection{Almost Rings}
While the stated domain of the solver is simply ``commutative rings'', it turns
out that we can be slightly more flexible than that if we pick our algebra
carefully.
As in \citet[section~5]{gregoire_proving_2005}, we use an algebra called an
\emph{almost-ring}. It has the regular operations (\(+\), \(*\)
(multiplication), \(-\), \(0\), and \(1\)), such that the following equations
hold:
\begin{multicols}{2}
  \noindent
  \begin{align}
    0 + x       &= x \\
    x + y       &= y + x \\
    x + (y + z) &= (x + y) + z \\
    1 * x       &= x \\
    x * y       &= y * x
  \end{align}
  \begin{align}
    x * (y * z) &= (x * y) * z \\
    (x + y) * z &= x * z + y * z \\
    0 * x       &= 0 \label{semiring} \\
    -(x * y)    &= - x * y \label{ringmul} \\
    -(x + y)    &= -x + -y \label{ringadd}
  \end{align}
\end{multicols}
The equations up to \ref{semiring} represent a pretty standard definition of a
(commutative) semiring. From there, though, things are different. The normal
definition of a commutative ring would have (instead of \ref{ringmul} and
\ref{ringadd}) the following:
\begin{align}
  x + - x     &= 0
\end{align}
However, by choosing these slightly more complex laws, we can admit types like
\(\Nat\) which don't have additive inverses. Instead, these types can simply
supply the identity function for \(-\), and then \ref{ringmul} and \ref{ringadd}
will still hold.

A potential worry is that because we don't require \(x + -x = 0\) axiomatically,
it won't be provable in our system. Happily, this is not the case: as long as
\(1 + -1\) reduces to \(0\) in the coefficient set, the solver will verify the
identity.

In the library, the algebra is represented by the
\(\AgdaDatatype{AlmostCommutativeRing}\) type, a record with fields for each of
the ring axioms, defined over a user-supplied equivalence relation. Just as in
Agda's current solver, we also ask for one extra function: a weakly decidable
predicate to test if a constant is equal to zero.
\begin{center}
  \ExecuteMetaData[../ReflexiveProcessRings.tex]{weak-dec}
\end{center}
This function is used to speed up some internal algorithms in the solver, but it
isn't an essential component. By making it \emph{weakly} decidable, we allow
users to skip it
(\(\AgdaFunction{is-zero}~=~\AgdaFunction{const}~\AgdaInductiveConstructor{nothing}\))
if their type doesn't support decidable equivalence, or provide it (and get the
speedup) if it does.
\subsection{Correctness}
The \(\AgdaFunction{correct}\) function amounts to a proof of soundness: i.e.,
the solver will only ever prove equations which are genuinely equivalent. We
have not, however, proven completeness (i.e., that every genuine equivalence
will be proven by our solver), and indeed it is not possible to do so.

In the internal representation of the solver, we prove several data structure
invariants (like sparsity) intrinsically.

The reflection-based interface is unproven, but this does not invalidate the
solver: any errors will be caught by the typechecker, meaning that we are still
prevented from proving things that are untrue.
\subsection{Flexibility}
The solver (including the interface) will work with any type which implements
\(\AgdaDatatype{AlmostCommutativeRing}\), as described above. Furthermore, we
prove \emph{equivalences} (rather than equalities), meaning that our solver will
work on custom setoids. A consequence of this particular genericity is the
step-by-step solutions described below.
\section{The Interface}
As stated in the introduction, we felt an easy-to-use interface was one of the
most important components of the library as a whole. Since we wanted to minimise
the amount a user would have to learn to use the solver, we kept the surface
area of the library quite small: aside from the
\(\AgdaDatatype{AlmostCommutativeRing}\) type described above, the rest of the
interface consists of just two macros (\(\AgdaMacro{solve}\) and
\(\AgdaMacro{solveOver}\)). We tried to make their usage as obvious as possible:
just stick one of them (with the required arguments) in the place you need a
proof, and the solver will do the rest for you.

\(\AgdaMacro{solve}\) is demonstrated in Fig.~\ref{the-solver}. It takes a
single argument: an implementation of the algebra. \(\AgdaMacro{solveOver}\) is
designed to be used in conjunction with manual proofs, so that a programmer can
automate a ``boring'' section of a larger more complex proof. It is called like
so:

\begin{centering}
  \ExecuteMetaData[../ReflectionSection.tex]{partial-auto}
\end{centering}

As well as the \(\AgdaDatatype{AlmostCommutativeRing}\) implementation, this
macro takes a list of free variables to use to compute the solution.

Because this interface is quite small, it's worth pointing out what's missing,
or rather, what we \emph{don't} require from the user:

\begin{itemize}
  \item We don't ask the user to construct the \(\AgdaDatatype{Expr}\) AST which
    represents their proof obligation. Compare this to Fig.~\ref{old-solver}: we
    had to write the type of the proof twice (once in the signature and again in
    the AST), and we had to learn the syntax for the solver's AST. 

    As well as being more verbose, this approach is less composable: every
    change to the proof type has to be accompanied by a corresponding change in
    the call to the solver. In contrast, the call to \(\AgdaMacro{solveOver}\)
    above effectively amounts to a demand for the compiler to ``figure it out!''
    Any change to the expressions on either side will result in an
    \emph{automatic} change to the proof constructed.
  \item We don't ask the user to write any kind of ``reflection logic'' for
    their type. In other words, we don't require a function which (for instance)
    recognises and parses the user's type in the reflected AST, or a function
    which does the opposite, converting a concrete value into the AST that (when
    unquoted) would produce an expression equivalent to the quoted value.

    This kind of logic is complex, and very difficult to get right. While some
    libraries can assist with the task \citep{hinze_engineering_2013,
      norell_agda-prelude_2018} it is still not fully automatic.
\end{itemize}
\subsection{Maintaining Invariants}
One of the great promises of languages like Agda is the ability to encode
program correctness in types, allowing programmers to \emph{prove} properties
they would have otherwise only been able to test. Unfortunately, these kinds of
proofs tend to be very tightly coupled to the implementation of the algorithms
they verify. This can make iteration difficult, where small optimisations or bug
fixes can invalidate proofs for other invariants.

To demonstrate the problem, and how our solver can reduce some of the burden,
we'll look at size-indexed binary trees:
\begin{center}
  \ExecuteMetaData[../Invariants.tex]{tree}
\end{center}
In contrast to size-indexed lists, this type is one you don't see very often in
Agda: the reason is that the index (the size) doesn't match the shape of the
data structure. As a result, almost every function which manipulates the tree in
someway will have to come accompanied by a verbose, complex proof.

Take this line, for instance, which performs a left-rotation on the tree:
\begin{center}
  \ExecuteMetaData[../Invariants.tex]{unproven}
\end{center}

A sensible invariant to encode here is that the function doesn't change the size
of the tree. Unfortunately, to \emph{prove} that invariant, we have to prove the
following:
\[1 + (1 + a + c) + b = 1 + a + (1 + b + c)\]

Though simple, this is precisely the kind of proof which requires many fussy
applications of the ring axioms. Here, our solver can help:
\begin{center}
  \ExecuteMetaData[../Invariants.tex]{mistake}
\end{center}

While cutting down on the amount of code we need to write is always a good
thing, the real strength of this method is that it automatically infers the
input type. This makes it resilient to small changes in the code. So, when we
notice the bug in the code above (\(yl\) and \(yr\) are swapped in the
pattern-match), we can simply \emph{fix it}, without having to touch any of the
proof code.
\begin{center}
  \ExecuteMetaData[../Invariants.tex]{correct}
\end{center}

If we hadn't used the solver, this fix would have necessitated a totally new
proof. By automating the proof, we allow the compiler to automatically check
what we \emph{mean} (``does the size of the tree stay the same?''), while we
worry about other details.
\subsection{Reflection}
Agda has powerful metaprogramming facilities, which allow programs to manipulate
their own code. Here, we'll use reflection to implement the interface to our
solver.

Agda's reflection API is mostly encapsulated by the following three types:
\begin{description}
  \item[\(\AgdaDatatype{Term}\)] The representation of Agda's AST, retrievable
    via \(\AgdaKeyword{quoteTerm}\).
  \item[\(\AgdaDatatype{Name}\)] The representation of identifiers, retrievable
    via \(\AgdaKeyword{quote}\).
  \item[\(\AgdaDatatype{TC}\)] The type-checker monad, which includes scoping
    and environment information, can raise type errors, unify variables, or
    provide fresh names. Computations in the \(\AgdaDatatype{TC}\) monad can be
    run with \(\AgdaKeyword{unquote}\).
\end{description}

While \(\AgdaKeyword{quote}\), \(\AgdaKeyword{quoteTerm}\), and
\(\AgdaKeyword{unquote}\) provide all the functionality we need, they're
somewhat low-level and noisy (syntactically speaking). Agda also provides a
mechanism (which it calls macros) to package metaprogramming code so it looks
like a normal function call (as in \(\AgdaMacro{solve}\)).

Reflection is obviously a powerful tool, but it has a reputation for being
unsafe and error-prone. Agda's reflection system doesn't break type safety, but
we \emph{are} able to construct \(\AgdaDatatype{Term}\)s which are ill-typed,
which often result in confusing error-messages on the user's end. Unfortunately,
constructing ill-typed terms is quite easy to do: the \(\AgdaDatatype{Term}\)
type itself doesn't contain a whole lot of type information, and it's quite
fragile and sensitive to context. Variables, for instance, are referred to by
their de Bruijn indices, meaning that the same \(\AgdaDatatype{Term}\) can break
if it's simply moved under a lambda.

Building a robust interface using reflection required a great deal of care. To
demonstrate some of the techniques we used, we'll look at two functions from the
core of the interface. First, \(\AgdaFunction{toExpr}\):
\begin{center}
  \ExecuteMetaData[../ReflectionSection.tex]{to-expr}
\end{center}
This function is called on the \(\AgdaDatatype{Term}\) representing one side of
the target equivalence. It converts it to the corresponding
\(\AgdaDatatype{Expr}\). In other words, it performs the following
transformation:
\[
  \includegraphics[trim={25 14 28 10}]{graphics/lhs-expr}
  \dashrightarrow
  \includegraphics[trim={25 14 22 10}]{graphics/lhs-ast}
\]

When it encounters one of the ring operators, it calls the corresponding helper
function (\(\AgdaFunction{getBinOp}\), \(\AgdaFunction{getExp}\), or
\(\AgdaFunction{getUnOp}\)) which finds the important subterms from the
operator's argument list.

If it \emph{doesn't} manage to match an operator or a variable, it assumes that
what it has must be a constant, and wraps it up in the
\(\AgdaInductiveConstructor{K}\) constructor. This is the key trick which allows
us to avoid ever asking the user to quote their own type. While it may seem
unsafe at first glance, we actually found it to be more robust (for our use
case) than the alternative:
\begin{principle}[Don't reimplement the typechecker] While it may seem good and
  fastidious to rigorously check the structure and types of arguments given to a
  macro, we found in general it was a \emph{bad} idea to do validity-checking in
  metaprogramming code. Instead, we preferred to proceed as if there were no
  errors (if possible), but arrange the output so that the user would still see
  a type error where the input was incorrect.

  Taking this case as an example, if the user indeed manages to supply something
  other than the correct type, Agda will catch the error, as an incorrect
  argument to \(\AgdaInductiveConstructor{K}\).

  If, on the other hand, we had asked the user to quote their own type, we
  would have trouble handling (for instance) closed applications of functions,
  references to names outside the lambda, etc. This approach, on the other hand,
  has no such difficulty.
\end{principle}

Next, we'll look at one of the helper functions: \(\AgdaFunction{getExp}\),
which deals with exponentiation.
\begin{center}
  \ExecuteMetaData[../ReflectionSection.tex]{getExp}
\end{center}

It extracts the last two arguments to the exponentiation operator, and wraps
them up with the \(\AgdaInductiveConstructor{⊛}\). Something worth noticing is
that it doesn't care how long the list actually is, it only looks for the last
two arguments. Again, we found that this looseness was actually a benefit:

\begin{principle}[Don't assume structure] In this example, as well as elsewhere,
  to find arguments to an \(n\)-ary function we to simply extract the last \(n\)
  visible arguments to the function. While in theory we might be able to
  statically know all of the implicit and explicit arguments that will be used
  at the call-site, it's much simpler to ignore them, and try our best to be
  flexible. Remember, none of this is typed, so if something changes (like, say,
  a new universe level in \(\AgdaDatatype{AlmostCommutativeRing}\)), you'll get
  type errors where you call \(\AgdaMacro{solve}\), not where it's implemented.
\end{principle}

The next thing to point out is \(\AgdaNumber{3} \; \AgdaFunction{⋯⟅∷⟆}\).
This applies three hidden arguments as ``unknown'', i.e. asks Agda to infer
them. We could guess them ourselves: the first is the universe level of the
carrier type, the second is the carrier type, and the third is the number of
variables in the expression; however, we advise being as \emph{in}specific as
possible, relying on the compiler to guess where you can:

\begin{principle}[Supply the minimal amount of information] There were several
  instances where, in constructing a term, we were tempted to supply explicitly
  some argument that Agda usually infers. Universe levels were a common example.
  In general, though, this is a bad idea: AST manipulation is fragile and
  error-prone, so the chances that you'll get some argument wrong are very high.
  Instead, you should \emph{leverage} the compiler, relying on inference over
  direct metaprogramming as much as possible.
\end{principle}

The final point to make is that the entire interface implementation is itself
quite small (fewer than 100 lines). This isn't because our code was terse:
rather, we intentionally minimised the amount of metaprogramming we did:

\begin{principle}[Try and implement as much of the logic outside of reflection
  as possible] With great power comes poor error messages, fragility, and a loss
  of first-class status. Therefore, If something can be done without reflection,
  \emph{do it}, and use reflection as the glue to get from one standard
  representation to another.
\end{principle}
\section{Performance}
Type-checking proof-heavy Agda code is notoriously slow, so the solver had to be
carefully optimised to avoid being so slow as to be unusable. We'll start by
first describing the unoptimised solver, and demonstrate how to improve its
performance iteratively.
\subsection{Horner Normal Form}
The representation used in Agda's current ring solver (and the one we'll start
out with here) is known as Horner Normal Form. A polynomial (more specifically,
a monomial) in \(x\) is represented as a list of coefficients of increasing
powers of \(x\). As an example, the following polynomial:
\begin{align}
  3 + 2x^2 + 4x^5 + 2x^7 \label{example-poly}
\end{align}
Is represented by this list:
\begin{center}
  \ExecuteMetaData[../HornerNormalForm.tex]{dense-example}
\end{center}
Operations on these polynomials are similar to operations in positional number
systems.
\begin{multicols}{2}
  \ExecuteMetaData[../HornerNormalForm.tex]{impl}
\end{multicols}
And finally, evaluation of the polynomial (given \(x\)) is a classic example of
the \(\AgdaFunction{foldr}\) function.
\begin{center}
  \ExecuteMetaData[../HornerNormalForm.tex]{eval}
\end{center}
\subsection{Sparse Encodings}
Our first avenue for optimisation comes from \citet{gregoire_proving_2005}.
Notice that the encoding above is quite wasteful: it always stores an entry for
each coefficient, even if it's zero. In practice, we're likely to often find
long strings of zeroes (in expressions like \(x^{10}\)), meaning that our
representation will contain long ``gaps'' between the coefficients we're
actually interested in (non-zero ones).

To fix the problem we'll switch to a \emph{sparse} encoding, by storing a
``power index'' with every coefficient.
\begin{center}
  \ExecuteMetaData[../HornerNormalForm.tex]{sparse-poly}
\end{center}

This will represent the size of the gap from the previous non-zero coefficient.
Taking \ref{example-poly} again as an example, we would now represent it as
follows: 
\begin{center}
  \ExecuteMetaData[../HornerNormalForm.tex]{sparse-example}
\end{center}

Next, we turn our attention to the task of adding multiple variables. Luckily,
there's an easy way to do it: nesting. Multivariate polynomials will be
represented as ``polynomials of polynomials'', where each level of nesting
corresponds to one variable. It's perhaps more clearly expressible in types:
\begin{center}
  \ExecuteMetaData[../HornerNormalForm.tex]{multi}
\end{center}
Inductively speaking, a ``polynomial'' in 0 variables is simply a constant,
whereas a polynomial in \(n\) variables is a list of coefficients, which are
themselves polynomials in \(n-1\) variables.

Before running off to use this representation, though, we should notice that we
have created another kind of ``gap'' which we should avoid with a sparse
encoding. For a polynomial with \(n\) variables, we will always have \(n\)
levels of nesting, even if the polynomial doesn't actually refer to all \(n\)
variables. In the extreme case, representing the constant \(6\) in a polynomial
of 3 variables looks like the following:
\begin{center}
  \ExecuteMetaData[../HornerNormalForm.tex]{multi-nest}
\end{center}

The solution is another index: this time an ``injection'' index. This represents
``how many variables to skip over before you get to the interesting stuff''. In
contrast to the previous index, though, this one is type-relevant: we can't just
store a \(\Nat\) next to the nested polynomial to represent the gap. Because the
polynomial is indexed by the number of variables it contains, any encoding of
the gap will have provide the proper type information to respect that index.
\subsection{Hanging Indices}
The problem is a common one: we have a piece of code that works efficiently,
and we now want to make it ``more typed'', by adding more information to it,
\emph{without} changing the complexity class.

We found the following strategy to be useful: first, write the untyped version
of the code, forgetting about the desired invariants as much as possible. Then,
to add the extra type information, look for an inductive type which participates
in the algorithm, and see if you can ``hang'' some new type indices off of it.

In our case, the injection index (distance to the next ``interesting''
polynomial) was simply stored as an \(\Nat\), and the information we
needed was the number of variables in the inner polynomial, and the number of
variables in the outer. All of that is stored in the following proof of \(\le\):

\begin{center}
  \ExecuteMetaData[../EfficiencyInIndexedTypes.tex]{leq-3}
\end{center}

A value of type \(n \; \AgdaDatatype{≤} \; m\) mimics the inductive structure of
the \(\Nat\) we were storing to represent the distance between \(n\)
and \(m\). We were able to take this analogy quite far: in a few functions, for
instance, we needed to compare these gaps. By mimicking the inductive structure
of \(\Nat\), we were able to directly translate \(\AgdaDatatype{Ordering}\) and
\(\AgdaFunction{compare}\) on \(\Nat\):

\begin{center}
  \ExecuteMetaData[../EfficiencyInIndexedTypes.tex]{ord-type}
\end{center}

into equivalent functions on \(\le\):

\begin{multicols}{2}
  \ExecuteMetaData[../EfficiencyInIndexedTypes.tex]{leq-compare}
\end{multicols}
\subsection{Unification}
So far, our optimisations have focused on the \emph{operations} performed on the
polynomial. Remember, though, the reflexive proof process has several steps:
only one of them containing the operations (\(\AgdaFunction{⟦\_⇓⟧}\) in
Fig.~\ref{proof-process}).

As it happens, we have now optimised these operations so much that they are no
longer the bottleneck in the process. Surprisingly, the innocuous-looking
\(\AgdaInductiveConstructor{refl}\) now takes the bulk of the time! Typechecking
this step involves unifying the two normalised expressions, a task which is
quite expensive, with counterintuitive performance characteristics. So
counterintuitive, in fact, that early versions of the solver, with all the
optimisations from \citet{gregoire_proving_2005} applied, was in many cases
\emph{slower} than the old, unoptimised solver!

In this section, we'll try and explain the problem and how we fixed it, and give
general guidelines on how to write Agda code which typechecks quickly.

First, the good news. In the general case, unifying two expressions takes time
proportional to the size of those expressions, so our hard-won optimisations do
indeed help us.

Unfortunately, though, the ``general case'' isn't really that general: Agda's
unification algorithm has a very important shortcut which we \emph{must} make
use of if we want our code to typecheck quickly: \emph{syntactic equivalence}.

Because Agda is a dependently-typed language, types can contain functions,
variables, and all sorts of complex expressions. One might expect that the
unification algorithm should compute these expressions as far as it can, getting
them to normal form, before it checks for any kind of equivalence. This would be
disastrous for performance! Consider the following:
\[ \AgdaFunction{sum} \; [ \AgdaNumber{1} .. \AgdaNumber{100} ] \stackrel{?}{=}
  \AgdaFunction{sum} \; [ \AgdaNumber{1} .. \AgdaNumber{100} ] \]

Running both computations here is an unnecessarily expensive task, and one which
Agda does indeed avoid. Before the full unification algorithm, the typechecker
does a quick pass to spot any syntactic equalities like the one above: if it
sees one, it can avoid any more computation on that particular expression.

Taking advantage of that shortcut is key to achieving decent performance. With
that in mind, there are two main strategies we'll use to encourage syntactic
equivalence:
\subsubsection{Avoid Progress at all Costs}
First, we will consider something which may seem inconsequential: the order of
arguments to the evaluation functions.
\begin{multicols}{2}
  \centering
  \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{forwards-eval}
  \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{backwards-eval}
\end{multicols}
\(\AgdaFunction{⟦\_⟧ₗ}\) is the definition we've been working with so far. Some
readers might find \(\AgdaFunction{⟦\_⟧ᵣ}\) more natural, however. The reason is
that it's more productive: in lazy languages, the usual convention is that
functions which take multiple arguments should scrutinise those arguments from
left to right. The \(\AgdaFunction{*}\) and \(\AgdaFunction{+}\) functions (on
\(\Nat\), at any rate) follow that convention, meaning that
\(\AgdaFunction{⟦\_⟧ᵣ}\) is able to make more progress without a concrete \(x\).
Taking the polynomial \(x^2 + 2\) as an example:
\begin{multicols}{2}
  \centering
  \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{for-progress}
  \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{back-progress}
\end{multicols}
In \(\AgdaFunction{⟦\_⟧ₗ}\), we're blocked pretty much straight away, as \(x\)
is the first thing we try to scrutinise. In \(\AgdaFunction{⟦\_⟧ᵣ}\), since all
of the constants are kept to the left, they're scrutinised first, allowing us to
perform much more normalisation before being blocked.

Surprisingly, this is exactly what you \emph{don't} want! Since both sides of
the equation will be coming out of the same normalisation function, they should
have similar structures, allowing for syntactic equivalence. The coefficients,
though, will be computed during manipulations on the Horner normal form, and so
may contain unevaluated expressions, which require normalisation. If we used
\(\AgdaFunction{⟦\_⟧ᵣ}\) as our definition, then, the typechecker will likely
hit an inequivalence very early on, and give up on syntactic equivalence. Even worse,
because it's able to make progress, it will likely do so, completely changing
the structure of the expression and ruining any chance for later syntactic
equalities!

The (counterintuitive) lesson learned is as follows: to speed up unification,
keep things which are likely to be syntactically equal to the left, and
\emph{don't} structure your functions to encourage progress. Simply swapping the
arguments (as we do above) resulted in a performance improvement of several
orders of magnitude.
\subsubsection{Avoid Constants}
\begin{figure}[h]
  \centering
  \begin{subfigure}{0.4\textwidth}
    \centering
    \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{dense-term}
    \caption{Dense encoding, without identity-avoiding optimisation}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \centering
    \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{small-force}
    \caption{Sparse encoding, with identity-avoiding optimisation}
  \end{subfigure}
  \caption{Comparison of the normal forms of equation~\ref{example-poly}}
  \label{normal-forms}
\end{figure}
It's a good idea to avoid constant coefficient expressions in the normal form.
This will reduce the size of your expression, which is helpful in general, but
more importantly it will make it less likely that the typechecker will be able
to run some normalisation on one of the ring operators.

Our sparse representation helps significantly in this case: by removing
\(\AgdaNumber{0}\) from the generated expression, we significantly improve the
chances of maintaining structural similarity between the two normal forms.

Another place we can cut down on constants is in identity elements in the base
case for recursive functions. Take exponentiation, for example:
\begin{center}
  \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{pow-bad}
\end{center}
We can avoid that \(\AgdaNumber{1}\) in the majority of cases by rewriting the
function to have an extra base case:
\begin{multicols}{2}
  \centering
  \ExecuteMetaData[../PerformanceOfTypeChecking.tex]{pow-ident}
\end{multicols}
In the library, we employ this idea extensively, avoiding unnecessary identities
as much as we could. This has a significant effect on the size of the resulting
normal form, but also ensures that normalisation stops exactly where we want it
to, preserving the structure of the expressions as much as is possible. This
makes a significant difference to both size and syntactic
similarity as can be seen in Fig.~\ref{normal-forms}.
\subsection{Verifying the Optimisations}
The output of the solver is a constructive proof of equivalence: this is
\emph{derived} from a generic proof that the operations on the solver are a ring
homomorphism from the carrier type. Put another way, for the solver to work
properly, we would need to prove that addition (and multiplication, and
negation, etc.) on Horner normal forms corresponds with addition on the carrier
type.

These proofs are long (about 1000 lines) and complex. Without careful
structuring of the proofs, every new optimisation would require a whole new
round of proof code, with very little reuse.

To avoid this problem, we took inspiration from \citet{mu_algebra_2009}, and
relied heavily on abstraction and folds to improve the reuse in proof code. In
particular, we defined many operations as \emph{metamorphisms}
\cite{gibbons_metamorphisms_2007}. So, instead of defining (say) negation over
the polynomial type itself, we will define a metamorphism to express negation,
and then call some higher-order function to run that metamorphism over a
polynomial.
\begin{center}
  \ExecuteMetaData[../AbstractionAndFolds.tex]{fold-def}
\end{center}
From here, we can define the \emph{semantics} of a metamorphism. As an example,
here are the semantics of \(\AgdaFunction{mapR}\), a simple morphism which
behaves something like \(\AgdaFunction{map}\) on lists:

\begin{center}
  \ExecuteMetaData[../AbstractionAndFolds.tex]{poly-mapR}
\end{center}

Now, each operation only has to be proven up to the semantics defined above.
Crucially, optimisations like the sparse encoding \emph{respect} these
semantics, so we only have to change our proof in one place: the definition of
\(\AgdaFunction{poly-mapR}\).
\subsection{Benchmarks}
As expected, the sparse implementation exhibits a significant speedup in
type-checking over the dense implementation, even with the added overhead of the
reflection-based interface. Fig.~\ref{bench1} shows time taken to type check a
proof that \((x_1 + x_2 + x_3 + x_4 + x_5)^d\) is equal to its expanded form.
The sparse representation is clearly faster overall, with a factor of 7.5
speedup for \(d = 8\).

Fig.~\ref{bench2} demonstrates where some of the speedup might come
from. The expression \(x^d\) is represented very differently in the two
implementations: in the sparse encoding, it's a single-element list containing a
tuple of $1$ and $d$; in the dense encoding, however, it's a list of length $d$,
with a single $1$ at the end. Since the complexities of arithmetic operations
are bounded by the length of the list, this explains the difference in cost of
the addition operations.

Fig.~\ref{bench3} demonstrates perhaps a more common use-case, with a mix of
high and low powers and some constants. The sparse representation's advantage is
even more apparent here, with an \(30\)-factor speedup at \(d = 8\).

The dense solver does exhibit a small lead (roughly 2-3 seconds, which narrows
to about 1 second without reflection) on very simple expressions, possibly
caused by the overhead of the sparse solver's more complex implementation. 3
seconds is quite small in the context of Agda type checking (the standard
library, for instance, takes several minutes to type check), so we feel this
slight loss is more than made up for by the several-minute gains. Furthermore,
we have not been able to find a case where the dense solver is significantly
faster than the sparse. Nonetheless, if a user really wants to use the dense
solver, the other components described here are entirely modular, and can work
with any underlying solver which uses the reflexive technique.
\begin{figure}
  \newcounter{realxtickpos}
  \pgfplotsset{
      tick label style={font=\scriptsize},
      extra y tick style={yticklabel pos=right},
      title style={at={(-0.03,1.05)},anchor=west},
      xticklabel={%
        \ifnum \value{realxtickpos}=0%
          {$d = \pgfmathprintnumber{\tick}$}
        \else
          {$\pgfmathprintnumber{\tick}$}
        \fi
        \stepcounter{realxtickpos}
      },
      width=1.2\textwidth,
  }
  \setcounter{realxtickpos}{0}
  \begin{subfigure}[t]{0.3\textwidth}
    \begin{tikzpicture}
      \begin{axis}[
        legend columns=-1,
        legend entries={new, old},
        legend to name=benchplots,
        extra y ticks={15},
        title={(\subref{bench1}) $(x_1 + x_2 + \ldots + x_n)^d$},
        ]
        \addplot[color=blue, densely dashed] table {../benchmark-data/sparse1.dat};
        \addplot[color=red] table {../benchmark-data/dense1.dat};
      \end{axis}
    \end{tikzpicture}
    \phantomcaption \label{bench1}
  \end{subfigure}
  \setcounter{realxtickpos}{0}
  \begin{subfigure}[t]{0.3\textwidth}
    \begin{tikzpicture}
      \begin{axis}[
        extra y ticks={5},
        title={(\subref{bench2}) $x_1^d + x_2^d + \ldots + x_n^d$},
        ]
        \addplot[color=blue, densely dashed] table {../benchmark-data/sparse2.dat};
        \addplot[color=red] table {../benchmark-data/dense2.dat};
      \end{axis}
    \end{tikzpicture}
    \phantomcaption\label{bench2}
  \end{subfigure}
  \setcounter{realxtickpos}{0}
  \begin{subfigure}[t]{0.3\textwidth}
    \begin{tikzpicture}
      \begin{axis}[
        extra y ticks={40},
        title={(\subref{bench3}) $(x_1^n + x_2^{n-1} + \ldots + x_n^1 + 1)^d$},
        ]
        \addplot[color=blue, densely dashed] table {../benchmark-data/sparse3.dat};
        \addplot[color=red] table {../benchmark-data/dense3.dat};
      \end{axis}
    \end{tikzpicture}
    \phantomcaption\label{bench3}
  \end{subfigure}
  \ref{benchplots}
  \parbox{0.9\textwidth}{
    \begin{flushleft}
      \caption{Time (in seconds) to prove each expression is equal to its expanded
        form ($n = 5$ for each).}
      \smallskip
      \footnotesize
      Benchmarks performed on Agda version 2.6-0fa9b13, with the Agda standard
      library at commit-3bd3334a9552490e396f73f96812105a27e5917b, on a 2016
      MacBook Pro, with a 2.9 GHz Intel Core i7 and 16 GB of RAM.
    \end{flushleft}
  }
  \label{benchmarks}
\end{figure}
\section{Pedagogical Solutions}
One of the most widely-used and successful computer algebra systems, especially
among non-programmers, is Wolfram|Alpha
\cite{wolfram_research_inc._wolframalpha_2019}. It can generate ``pedagogical''
(step-by-step) solutions to maths
problems \cite{the_development_team_step-by-step_2009}. For instance, given the
input \(x^2 + 5 x + 6 = 0\), it will give the following output:
\begin{align*}
  x^2 + 5x + 6   = 0 \\
  (x + 2)(x + 3) = 0 \\
  x + 2 = 0   \; \text{or} \; x + 3 = 0 \\
  x     = -2  \; \text{or} \; x + 2 = 0 \\
  x     = -2  \; \text{or} \; x     = -3
\end{align*}

These tools can be invaluable for students learning basic mathematics.
Unfortunately, much of the software capable of generating usable solutions is
proprietary (including Wolfram Alpha), and little information is available as to
their implementation techniques. \citet{lioubartsev_constructing_2016} is perhaps
the best current work on the topic, but even so very little work exists in the
way of the theoretical basis for pedagogical solutions.

\citet{lioubartsev_constructing_2016} reformulates the problem as one of
\emph{path-finding}. The left-hand-side and right-hand-side of the equation are
vertices in a graph, where the edges are single steps to rewrite an expression
to an equivalent form. A* is used to search.

Unfortunately, this approach has to deal with a huge search space: every vertex
will have an edge for almost every one of the ring axioms, and as such a good
heuristic is essential. Furthermore, what this should be is not clear:
\citet{lioubartsev_constructing_2016} uses a measure of the ``simplicity'' of an
expression.

So, with an eye to using our solver to help, we can notice that paths in
undirected graphs form a perfectly reasonable equivalence relation: transitivity
is the concatenation of paths, reflexivity is the empty path, and symmetry is
\emph{reversing} a path. Equivalence classes, in this analogy, are connected
components of the graph.

More practically speaking, we implement these ``paths'' as lists, where the
elements of the list are elementary ring axioms. When we want to display a
step-by-step solution, we simply print out each element of the list in turn,
interspersed with the states of the expression (the vertices in the graph).
\begin{multicols}{2}
  \ExecuteMetaData[../SetoidApplications.tex]{traced}
\end{multicols}
\begin{wrapfigure}{r}{0.3\textwidth}
  \centering
  \resizebox{0.35\textwidth}{!}{
    \begin{tikzpicture}
      \node (n0) at (2,9) {$1 + 2 + y + x$};
      \node (n1) at (-2,6) {$x + y * 1 + 3$};
      \node (n2) at (2,7.5) {$3 + y + x$};
      \node (n3) at (2,6) {$y + 3 + x$};
      \node (n4) at (0,4.5) {$x + y + 3$};
      \node (n5) at (-1,3) {$3 + x + y$};
      \node (n6) at (1,3) {$x + 3 + y$};
      \draw[-stealth] (n1) to (n4);
      \draw[-stealth] (n3) to (n2);
      \draw[-stealth] (n2) to (n0);
      \draw[-stealth] (n4) to (n3);
      \draw[-stealth] (n4) to (n5);
      \draw[-stealth] (n5) to (n6);
      \draw[-stealth] (n6) to (n4);
    \end{tikzpicture}
  } \caption{Hourglass-Shaped Graph}
  \label{h-graph}
\end{wrapfigure}
If we stopped there, however, the solver would output incredibly verbose
``solutions'': far too verbose to be human-readable. Instead, we must apply a
number of path-compression heuristics to cut down on the solution length:

\begin{enumerate}
  \item First, we run (a version of) Dijkstra's algorithm on the generated path.
    Fig~\ref{h-graph} shows an example solution without this heuristic applied: 
    it crosses the same point multiple times, creating the kind of loops we want
    to avoid. In contrast to using just A* on its own, the search space is
    minimal (with only one outward edge for each vertex).
  \item Then, we filter out ``uninteresting'' steps. These are steps which are
    obvious to a human, like associativity, or evaluation of closed terms. When
    a step is divided over two sides of an operator, it is deemed
    ``interesting'' if either side is interesting.
\end{enumerate}

After applying those heuristics, our solver outputs the following for the lemma
in Fig.~\ref{the-solver}:
\begin{center}
\begin{BVerbatim}
x + y * 1 + 3
    ={ eval }
x + y + 3
    ={ +-comm(x,y + 3) }
y + 3 + x
    ={ +-comm(y,3) }
3 + y + x
    ={ eval }
2 + 1 + y + x
\end{BVerbatim}
\end{center}
Figuring out good heuristics and path compression techniques seems to deserve
further examination.
\section{Related Work}
In dependently-typed programming languages, the state-of-the-art solver for
polynomial equalities (over commutative rings) was originally presented
in \citet{gregoire_proving_2005}, and is used in Coq's \verb+ring+ solver. This
work improved on the already existing solver \cite{Coq:manual} in both efficiency
and flexibility. In both the old and improved solvers, a reflexive technique is
used to automate the construction of the proof obligation (as described in
\citet{boutin_using_1997}).

Agda \cite{norell_dependently_2008} is a dependently-typed programming language
based on Martin-Löf's Intuitionistic Type
Theory \cite{martin-lof_intuitionistic_1980}. Its standard
library \cite{danielsson_agda_2018} currently contains a ring solver which is
similar in flexibility to Coq's \verb+ring+, but doesn't support the
reflection-based interface, and is less efficient to the one presented here. 

In \citet{geuvers_automatically_2017}, an implementation of an automated solver
for the dependently-typed language Idris \cite{brady_idris_2013} is described.
The solver is implemented with a ``correct-by-construction'' approach, in
contrast to \citet{gregoire_proving_2005}. The solver is defined over
\emph{non}commutative rings, meaning that it is more general (can work with more
types) but less powerful (meaning it can prove fewer identities). It provides a
reflection-based interface, but internally uses a dense representation.

Reflection and metaprogramming are relatively recent additions to Agda, but form
an important part of the interfaces to automated proof procedures. Reflection in
dependent types in general is explored in \citet{christiansen_practical_2015},
and specific to Agda in \citet{van_der_walt_reflection_2012}.

Formalisation of mathematics in general is an ongoing project.
\citet{wiedijk_formalizing_2018} tracks how much of ``The 100 Greatest Theorems''
\cite{kahl_hundred_2004} have so far been formalised (at time of writing, the
number stands at 93). DoCon \cite{meshveliani_docon-provable_2018} is a notable
Agda library in this regard: it contains many tools for basic maths, and
implementations of several CAS algorithms. Its implementation is described
in \citet{meshveliani_dependent_2013}. \citet{cheng_functional_2018} describes the
manipulation of polynomials in both Haskell and Agda.

Finally, the study of \emph{pedagogical} CASs which provide step-by-step
solutions is explored in \citet{lioubartsev_constructing_2016}. One of the most
well-known such system is Wolfram Alpha
\cite{wolfram_research_inc._wolframalpha_2019}, which has step-by-step solutions
\cite{the_development_team_step-by-step_2009}.

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{../bibliography.bib}
% %% Appendix
% \appendix
% \section{Appendix}

% Text of appendix \ldots

\end{document}
