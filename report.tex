\documentclass[draft, twocolumn]{article}
\usepackage{cite}
\usepackage{url}
\usepackage{catchfilebetweentags}
\usepackage{amssymb}
\usepackage{turnstile}
\usepackage{bbm}
\usepackage[greek, english]{babel}
\usepackage{MnSymbol}
\newcommand\doubleplus{+\kern-1.3ex+\kern0.8ex}
\newcommand\mdoubleplus{\ensuremath{\mathbin{+\mkern-8mu+}}}
\makeatletter
\newcommand\incircbin
{%
  \mathpalette\@incircbin
}
\newcommand\@incircbin[2]
{%
  \mathbin%
  {%
    \ooalign{\hidewidth$#1#2$\hidewidth\crcr$#1\bigcirc$}%
  }%
}
\newcommand{\oeq}{\ensuremath{\incircbin{=}}}
\makeatother
\usepackage{ucs}
\DeclareUnicodeCharacter{8759}{\ensuremath{\squaredots}}
\DeclareUnicodeCharacter{951}{\textgreek{\texteta}}
\DeclareUnicodeCharacter{737}{\ensuremath{^l}}
\DeclareUnicodeCharacter{691}{\ensuremath{^r}}
\DeclareUnicodeCharacter{8718}{\ensuremath{\blacksquare}}
\DeclareUnicodeCharacter{957}{\textgreek{\textnu}}
\DeclareUnicodeCharacter{961}{\textgreek{\textrho}}
\DeclareUnicodeCharacter{954}{\textgreek{\textkappa}}
\DeclareUnicodeCharacter{10214}{\ensuremath{\lsem}}
\DeclareUnicodeCharacter{10215}{\ensuremath{\rsem}}
\DeclareUnicodeCharacter{8857}{\mdoubleplus}
\DeclareUnicodeCharacter{8860}{\oeq}
\DeclareUnicodeCharacter{9043}{\ensuremath{\triangle}}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{autofe}
\usepackage{agda}
\usepackage{bbding}
\setlength{\marginparwidth}{2cm}
\usepackage[obeyDraft]{todonotes}
\author{D Oisín Kidney}
\title{An Efficient and Flexible Evidence-Providing Polynomial Solver in Agda}
\begin{document}
\maketitle
\begin{abstract}
  We provide an efficient implementation of a polynomial solver in the
  programming language Agda, and demonstrate its use in a variety of
  applications.
\end{abstract}
\tableofcontents
\section{Introduction}
Dependently typed languages such as Agda\cite{norell_dependently_2008} and
Coq\cite{the_coq_development_team_2018_1219885} allow programmers to write
machine-checked proofs as programs. They provide a degree of reassurance that
handwritten proofs cannot, and allow for exploration of abstract concepts in a
machine-assisted environment.

We will describe an efficient implementation of an automated prover for
equalities in ring and ring-like structures, and show how it can be extended for
use in settings more exotic than simple equality.
\section{Monoids}
Before describing the ring solver, first we will explain the simpler case of a
monoid solver.

A monoid is a set equipped with a binary operation, \(\bullet\), and a
distinguished element \(\epsilon\), which obeys the laws:
\begin{align}
  x \bullet (y \bullet z) &= (x \bullet y) \bullet z \tag{Associativity} \\
  x \bullet \epsilon      &= x \tag{Left Identity} \\
  \epsilon \bullet x      &= x \tag{Right Identity}
\end{align}
\subsection{Equality Proofs}
Monoids can be represented in Agda in a straightforward way, as a record (see
figure~\ref{mon-def}).
\begin{figure}
  \ExecuteMetaData[Monoids.tex]{mon-def}
  \caption{The definition of Monoid in the Agda Standard
    Library\cite{danielsson_agda_2018}}
  \label{mon-def}
\end{figure}

These come equipped with their own equivalence relation, according to which
proofs for each of the monoid laws are provided. Using this, we can prove
identities like the one in figure~\ref{mon-ident}.
\begin{figure}[h]
  \ExecuteMetaData[Monoids.tex]{mon-ident}
  \caption{Example Identity}
  \label{mon-ident}
\end{figure}

While it seems like an obvious identity, the proof is somewhat involved
(figure~\ref{mon-proof}).
\begin{figure}[!h]
  \ExecuteMetaData[Monoids.tex]{mon-proof}
  \caption{Proof of identity in figure~\ref{mon-ident}}
  \label{mon-proof}
\end{figure}

The syntax mimics that of normal, handwritten proofs: the successive ``states''
of the expression are interspersed with equivalence proofs (in the brackets).
Perhaps surprisingly, the syntax is not built-in: it's simply defined in the
standard library.

Despite the powerful syntax, the proof is mechanical, and it's clear that
similar proofs would become tedious with more variables or more complex algebras
(like rings). Luckily, we can automate the procedure.
\subsection{Canonical Forms}
Automation of equality proofs like the one above can be accomplished by first
rewriting both sides of the equation into a canonical form. This form depends on
the particular algebra used in the pair of expressions. For instance, a suitable
canonical form for monoids is lists.
\ExecuteMetaData[Monoids.tex]{list-def}

This type can be thought of as an AST for the ``language of lists''. Crucially,
it's equivalent to the ``language of monoids'': this is the language of
expressions written using only variables and the monoid operations, like the
expressions in figure~\ref{mon-ident}. The neutral element and binary operator
have their equivalents in lists: \(\epsilon\) is simply the empty list, whereas
\(\bullet\) is list concatenation.
\ExecuteMetaData[Monoids.tex]{list-monoid}

We can translate between the language of lists and monoid expressions
\footnote{
  For simplicity's sake, instead of curried functions of \(n\)
  arguments, we'll deal with functions which take a vector of length \(n\), that
  refer to each variable by position, using Fin, the type of finite sets. Of
  course these two representations are equivalent, but the translation is not
  directly relevant to what we're doing here: we refer the interested reader to
  the Relation.Binary.Reflection module of Agda's standard
  library\cite{danielsson_agda_2018}.
}
with \(\AgdaFunction{μ}\) and \(\AgdaFunction{η}\).
\ExecuteMetaData[Monoids.tex]{list-trans}

We have one half of the equality so far: that of the canonical forms. As such,
we have an ``obvious'' proof of the identity in figure~\ref{mon-ident},
expressed in the list language (figure~\ref{list-obvious}).
\begin{figure}[!h]
  \ExecuteMetaData[Monoids.tex]{list-obvious}
  \caption{The identity in figure~\ref{mon-ident}, expressed in the list
    language}
  \label{list-obvious}
\end{figure}
\subsection{Homomorphism}
Figure~\ref{list-obvious} gives us a proof of the form:

\begin{equation}
  \label{list-list}
  \text{lhs}_{list} = \text{rhs}_{list}
\end{equation}

What we want, though, is the following:

\begin{equation}
  \label{mon-mon}
  \text{lhs}_{mon} = \text{rhs}_{mon}
\end{equation}

Equation~\ref{list-list} can be used to build equation~\ref{mon-mon}, if we
supply two extra proofs:

\begin{equation}
  \text{lhs}_{mon} \overset{a}{=} \text{lhs}_{list} = \text{rhs}_{list}
  \overset{b}{=} \text{rhs}_{mon}
\end{equation}

The proofs labeled \(a\) and \(b\) are the task of this section.

First, we'll define a concrete AST for the monoid language
(figure~\ref{mon-ast}). It has constructors for each of the monoid operations
(\(\AgdaInductiveConstructor{⊕}\) and \(\AgdaInductiveConstructor{e}\) are
\(\bullet\) and \(\epsilon\), respectively), and it's indexed by the number of
variables it contains, which are constructed with \(\nu\). Converting back to an
opaque function is accomplished in figure~\ref{eval-ast}.

\begin{figure}
  \ExecuteMetaData[Monoids.tex]{mon-ast}
  \caption{The AST for the Monoid Language}
  \label{mon-ast}
\end{figure}
\begin{figure}
  \ExecuteMetaData[Monoids.tex]{eval-ast}
  \caption{Evaluating the Monoid Language AST}
  \label{eval-ast}
\end{figure}

Finally, then, we must prove the equivalence of the monoid and list languages.
This consists of the following proofs:

\begin{align}
  (\eta x) \mu \rho           &= \left\lsem \nu x \right\rsem \rho      \\
  (x \mdoubleplus y) \mu \rho &= \left\lsem x \oplus y \right\rsem \rho \\
  [] \mu \rho                 &= \left\lsem e \right\rsem \rho
\end{align}
The latter two proofs comprise a monoid homomorphism.

The proofs are constrained: we are only permitted to use the laws provided in
the Monoid record, and the equivalence relation is kept abstract. The fact that
we're not simply using propositional equality allows for some interesting
applications (see section~\ref{setoid-applications}), but it also removes some
familiar tools we may reach for in proofs. Congruence in particular must be
specified explicitly: the combinator \(\AgdaFunction{∙-cong}\) is provided for
this purpose. With this understood, the proofs can be written:
\ExecuteMetaData[Monoids.tex]{correct-ast}
\subsection{Usage}
Combining all of the components above, with some plumbing provided by the
Relation.Binary.Reflection module, we can finally automate the solving of the
original identity in figure~\ref{mon-ident}:
\ExecuteMetaData[Monoids.tex]{ident-auto-proof}
\subsection{Reflection}
One annoyance of the automated solver is that we have to write the expression we
want to solve twice: once in the type signature, and again in the argument
supplied to solve. Agda can infer the type signature:
\ExecuteMetaData[Monoids.tex]{ident-infer-proof}
But we would prefer to write the expression in the type signature, and have it
infer the argument to solve, as the expression in the type signature is the
desired equality, and the argument to solve is something of an implementation
detail.

\todo{Fill in reflection section} This inference can be accomplished using
Agda's reflection mechanisms.
\section{A Polynomial Solver}
We now know the components required for an automatic solver for some algebra: a
canonical form, a concrete representation of expressions, and a proof of
correctness. We now turn our focus to polynomials.

Prior work in this area includes\cite{geuvers_automatically_2017},
\cite{meshveliani_dependent_2013}, \cite{zalakain_evidence-providing_2017},
\cite{cheng_functional_2018}, and \cite{russino_polynomial_2017}, but perhaps
the state-of-the-art (at least in terms of efficiency) is Coq's \texttt{ring}
tactic\cite{the_coq_development_team_2018_1219885}, which is based on an
implementation described in\cite{hutchison_proving_2005}.

That implementation has a number of optimizations which dramatically improve the
complexity of evaluation, but it also includes a careful choice of algebra which
allows for maximum reuse. The choice of algebra has been glossed over thus far,
but it is an important design decision: choose one with too many laws, and the
solver becomes unusable for several types; too few, and we may miss out on
normalization opportunities.

The algebra defined in \cite{hutchison_proving_2005} is that of an
\emph{almost-ring}. This is a ring-like algebra, which discards the requirement
that negation is an inverse (\(x + (-x) = 0\)). Instead, it merely requires that
negation distribute over addiction and multiplication appropriately. This
allows the solver to be used with non-negative types, like \(\mathbb{N}\), where
negation is simply the identity function. Also, because the implementation uses
coefficients in the underlying ring, we lose no opportunities for normalization,
as identities like \(x + (-x) = 0\) will indeed compute.
\section{Horner Normal Form}
The canonical representation of polynomials is a list of coefficients, least
significant first (``Horner Normal Form''). Our initial attempt at encoding this
representation will begin like so:
\ExecuteMetaData[Rings.tex]{dense-opening}

The entire module is parameterized by the choice of coefficient. This
coefficient should support the ring operations, but it is ``raw'', i.e. it
doesn't prove the ring laws. The operations on the polynomial itself are defined
like so\footnote{
  Symbols chosen for operators use the following mnemonic:
  \begin{enumerate}
    \item Operators preceded with ``\(\mathbb{N}.\)'' are defined over
      \(\mathbb{N}\); e.g. \(\mathbb{N}.+\), \(\mathbb{N}.*\).
    \item Plain operators, like \(+\) and \(*\), are defined over the
      coefficients.
    \item Boxed operators, like \(\boxplus\) and \(\boxtimes\), are defined over
      polynomials.
    \item Operators which are boxed on one side are defined over polynomials on
      the corresponding side, and the coefficient on the other; e.g.
      \(\ltimes\), \(\rtimes\).
  \end{enumerate}
}:
\ExecuteMetaData[Rings.tex]{dense-impl}
\subsection{Sparse Horner Normal Form}
As it stands, the above representation has two problems:

\begin{description}
  \item[Redundancy] The representation suffers from the problem of trailing
    zeroes. In other words, the polynomial $2x$ could be represented by any of
    the following:
  
    \begin{align*}
      & 0, 2 \\
      & 0, 2, 0 \\
      & 0, 2, 0, 0 \\
      & 0, 2, 0, 0, 0, 0, 0
    \end{align*}
    
    This is a problem for a solver: the whole \emph{point} is that equivalent
    expressions are represented the same way.

  \item[Inefficiency] Expressions will tend to have large gaps, full only of
    zeroes. Something like $x^5$ will be represented as a list with 6 elements,
    only the last one being of interest. Since addition is linear in the length
    of the list, and multiplication quadratic, this is a major concern.
\end{description}

In\cite{hutchison_proving_2005}, the problem is addressed primarily from the
efficiency perspective: they add a field for the ``power index''. For our case,
we'll just store a list of pairs, where the second element of the pair is the
power index\footnote{
  In\cite{hutchison_proving_2005}, the expression \((c , i) \squaredots P\)
  represents \(P \times X^i + c\). We found that \(X^i \times (c + X \times P)\)
  is a more natural translation, and it's what we use here. A power index of
  \(i\) in this representation is equivalent to a power index of \(i+1\)
  in\cite{hutchison_proving_2005}.
}.

As an example, the polynomial:
\[ 3 + 2x^2 + 4x^5 + 2x^7 \]
Will be represented as:
\[ (3,0),(2,1),(4,2),(2,1) \]
Or, mathematically:
\[ x^0 (3 + x x^1 (2 + x x^2 * (4 + x x^1 (2 + x 0)))) \]
\subsubsection{Uniqueness}
While this form solves our efficiency problem, we still have redundant
representations of the same polynomials. In\cite{hutchison_proving_2005}, care
is taken to ensure all operations include a normalizing step, but this is not
verified: in other words, it is not proven that the polynomials are always in
normal form.

Expressing that a polynomial is in normal form turns out to be as simple as
disallowing zeroes: without them, there can be no trailing zeroes, and all gaps
must be represented by power indices. To check for zero, we require the user
supply a decidable predicate on the coefficients. This changes the module
declaration like so:
\ExecuteMetaData[Rings.tex]{sparse-opening}

Finally, we can define a sparse encoding of Horner Normal Form:
\ExecuteMetaData[Rings.tex]{sparse-decl}

The proof of nonzero is marked irrelevant (preceded with a dot) to avoid
computing it at runtime.

We can wrap up the implementation with a cleaner interface by providing a
normalizing version of \(\squaredots\):
\ExecuteMetaData[Rings.tex]{sparse-norm}
\subsubsection{Comparison}
Our addition and multiplication functions will need to properly deal with the
new gapless formulation. First things first, we'll need a way to match the power
indices. We can use a function from\cite{mcbride_view_2004} to do so.
\ExecuteMetaData[Rings.tex]{compare}
This is a classic example of a ``leftist'' function: after pattern matching on
one of the constructors of \(\AgdaDatatype{Ordering}\), it gives you information
on type variables to the \emph{left} of the pattern. In other words, when you
run the function on some variables, the result of the function will give you
information on its arguments.
\subsubsection{Efficiency}
The implementation of \(\AgdaFunction{compare}\) may raise suspicion with
regards to efficiency: if this encoding of polynomials improves time complexity
by skipping the gaps, don't we lose all of that when we encode the gaps as Peano
numbers?

The answer is a tentative no. Firstly, since we are comparing gaps, the
complexity can be no larger than that of the dense implementation. Secondly, the
operations we're most concerned about are those on the underlying coefficient;
and, indeed, this sparse encoding does reduce the number of those significantly.
Thirdly, if a fast implementation of \(\AgdaFunction{compare}\) is really and
truly demanded, there are tricks we can employ.

Agda has a number of built-in functions on the natural numbers: when applied to
closed terms, these call to an implementation on Haskell's \texttt{Integer}
type, rather than the unary implementation. For our uses, the functions of
interest are \(\AgdaFunction{-}\), \(\AgdaFunction{+}\), \(\AgdaFunction{<}\),
and \(\AgdaFunction{==}\). The comparison functions provide booleans rather than
evidence, but we can prove they correspond to the evidence-providing versions.
Combined with judicious use of \(\AgdaFunction{erase}\), we get the following:
\ExecuteMetaData[Rings.tex]{unsafe-compare}
\subsubsection{Termination}
Unfortunately, we cannot yet define addition and multiplication. Using
\(\AgdaFunction{compare}\) above in the most obvious way won't pass the
termination checker.
\ExecuteMetaData[Rings.tex]{nonterminating-addition}

Agda needs to be able to see that one of the numbers returned by
\(\AgdaFunction{compare}\) always reduces in size: however, since the difference
is immediately packed up in a list in the recursive call, it's buried too deeply
in constructors for the termination checker to see it.

The solution is twofold: unpack any constructors into function arguments as soon
as possible, and eliminate any redundant pattern matches in the offending
functions. Taken together, these form an optimization known as ``call pattern
specialization''\cite{jones_call-pattern_2007}: it's performed automatically in
GHC, here we're doing it manually. Perhaps a similar transformation could be
automatically applied before termination checking in Agda's compiler.

Until then, the structurally terminating function is defined like so:
\ExecuteMetaData[Rings.tex]{addition}
Ever helper function in the mutual block matches on exactly one argument,
eliminating redundancy. Happily, this makes the function more efficient, as well
as more obviously terminating.
\section{Binary}
Before continuing with polynomials, we'll take a short detour to look at binary
numbers. These have a number of uses in dependently typed programming: as well
as being a more efficient alternative to Peano numbers, their structure informs
that of many data structures, such as binomial heaps, and as such they're used
in proofs about those structures.

Similarly to polynomials, though, the naïve representation suffers from
redundancy in the form of trailing zeroes. There are a number of ways to
overcome this (see\cite{meshveliani_binary-4_2018}
and\cite{escardo_libraries_2018}, for example); yet another is the repurposing
of our sparse polynomial from above.
\ExecuteMetaData[Binary.tex]{binary-def}
We don't need to store any coefficients, because 1 is the only permitted
coefficient. Effectively, all we store is the distance to another 1.

Addition (elided here for brevity) is linear in the number of bits, as expected,
and multiplication takes full advantage of the sparse representation:
\ExecuteMetaData[Binary.tex]{binary-mul}
\section{Multivariate}
Up until now our polynomial has been an expression in just one variable. For it
to be truly useful, though, we'd like to be able to extend it to many: luckily
there's a well-known isomorphism we can use to extend our earlier
implementation. A multivariate polynomial is one where its coefficients are
polynomials with one fewer variable\cite{cheng_functional_2018}.
\subsection{Sparse}
\subsection{K}
\section{Setoid Applications} \label{setoid-applications}
\subsection{Traced}
\subsection{Isomorphisms}
\subsection{Counterexamples}
\section{The Correct-by-Construction Approach}
\bibliographystyle{IEEEtranS}
\bibliography{horners-rule.bib}
\end{document}