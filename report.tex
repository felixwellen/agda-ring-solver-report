\documentclass[draft, twocolumn]{article}
\usepackage{cite}
\usepackage{url}
\usepackage{catchfilebetweentags}
\usepackage{amssymb}
\usepackage{turnstile}
\usepackage{bbm}
\usepackage[greek, english]{babel}
\usepackage{MnSymbol}
\usepackage{csquotes}
\newcommand\doubleplus{+\kern-1.3ex+\kern0.8ex}
\newcommand\mdoubleplus{\ensuremath{\mathbin{+\mkern-8mu+}}}
\makeatletter
\newcommand\incircbin
{%
  \mathpalette\@incircbin
}
\newcommand\@incircbin[2]
{%
  \mathbin%
  {%
    \ooalign{\hidewidth$#1#2$\hidewidth\crcr$#1\bigcirc$}%
  }%
}
\newcommand{\oeq}{\ensuremath{\incircbin{=}}}
\makeatother
\usepackage{ucs}
\DeclareUnicodeCharacter{8759}{\ensuremath{\squaredots}}
\DeclareUnicodeCharacter{951}{\textgreek{\texteta}}
\DeclareUnicodeCharacter{737}{\ensuremath{^\text{l}}}
\DeclareUnicodeCharacter{691}{\ensuremath{^\text{r}}}
\DeclareUnicodeCharacter{8718}{\ensuremath{\blacksquare}}
\DeclareUnicodeCharacter{957}{\textgreek{\textnu}}
\DeclareUnicodeCharacter{961}{\textgreek{\textrho}}
\DeclareUnicodeCharacter{954}{\textgreek{\textkappa}}
\DeclareUnicodeCharacter{10214}{\ensuremath{\lsem}}
\DeclareUnicodeCharacter{10215}{\ensuremath{\rsem}}
\DeclareUnicodeCharacter{8857}{\mdoubleplus}
\DeclareUnicodeCharacter{8860}{\oeq}
\DeclareUnicodeCharacter{9043}{\ensuremath{\triangle}}
\DeclareUnicodeCharacter{928}{\textgreek{\textPi}}
\DeclareUnicodeCharacter{922}{\textgreek{\textKappa}}
\DeclareUnicodeCharacter{931}{\textgreek{\textSigma}}
\DeclareUnicodeCharacter{916}{\textgreek{\textDelta}}
\DeclareUnicodeCharacter{8779}{\ensuremath{\backtriplesim}}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{autofe}
\usepackage{agda}
\usepackage{bbding}
\setlength{\marginparwidth}{2cm}
\usepackage[obeyDraft]{todonotes}
\author{D Oisín Kidney}
\title{An Efficient and Flexible Evidence-Providing Polynomial Solver in Agda}
\begin{document}
\maketitle
\begin{abstract}
  We present a new implementation of a ring solver in the programming language
  Agda\cite{norell_dependently_2008}. The efficiency is improved over the
  version included in the standard library\cite{danielsson_agda_2018} by
  including optimizations described in\cite{hutchison_proving_2005}, among
  others.

  We demonstrate techniques for constructing proofs based on the theory of
  lists, show how Agda's reflection system can be used to provide a safe and
  simple interface to the solver, and compare the ``correct by construction''
  approach to that of auxiliary proofs.
  
  We also show that, as a by-product of proving equivalences rather than
  equalities, the generated proofs can be instantiated into a number of exotic
  settings, including:
  \begin{enumerate}
    \item Pretty-printing step-by-step solutions.
    \item Providing human-readable counterexamples when a proof fails.
    \item Constructing isomorphisms between types represented as polynomials.
  \end{enumerate}
\end{abstract}
\tableofcontents
\section{Introduction}
Dependently typed programming languages allow programmers and mathematicians
alike to write proofs which can be executed. For programmers, this often means
being able to formally verify the properties of their programs; for
mathematicians, it provides a system of machine-checked verification not
available to handwritten proofs.

Naïve usage of these systems can be tedious: the typechecker is often
over-zealous in its rigor, demanding justification for every minute step in a
proof, no matter how obvious or trivial it may seem to a human. For algebraic
proofs, this kind of thing usually consists of long chains of rewrites, of the
style ``apply commutativity of \(+\), then associativity of \(+\), then at this
position apply distributivity of \(*\) over \(+\)'' and so on, when really the
programmer wants to say ``rearrange the expression into this form, checking it's
correct''.

Luckily, since our proof assistant is also a programming language, we can
provide the desired capability, by writing a function which converts expressions
into a canonical form, and a proof that the conversion preserves the semantics
of the expression. This can then be used to automatically construct equivalence
proofs for equivalent expressions.
\section{A Case Study in Monoids}
Before describing the ring solver, first we will explain the technique of
writing a solver in Agda in the simpler case of monoids.

A monoid is a set equipped with a binary operation, \(\bullet\), and a
distinguished element \(\epsilon\), such that the following equations hold:
\begin{align}
  x \bullet (y \bullet z) &= (x \bullet y) \bullet z \tag{Associativity} \\
  x \bullet \epsilon      &= x \tag{Left Identity} \\
  \epsilon \bullet x      &= x \tag{Right Identity}
\end{align}
Addition and multiplication (with 0 and 1 being the respective identity
elements) are perhaps the most obvious candidates, as well as boolean
conjunction and disjunction. In computer science, monoids have proved a useful
abstraction for formalizing concurrency (associativity can be thought of as a
kind of ``order-independence'').

Monoids can be represented in Agda in a straightforward way, as a record (see
Figure~\ref{mon-def}). Immediately it should be noted that we're no longer
talking about a monoid over a set, but rather one over a setoid. In other words,
rather than using propositional equality (indicated by the \(\AgdaDatatype{≡}\)
symbol), we will use a user-supplied equivalence relation (\(\AgdaField{≈}\) in
Figure~\ref{mon-def}) in our proofs.
\begin{figure}
  \ExecuteMetaData[Monoids.tex]{mon-def}
  \caption{The definition of Monoid in the Agda Standard
    Library\cite{danielsson_agda_2018}}
  \label{mon-def}
\end{figure}
\subsection{Equivalence Proofs}
Propositions are stated in type signatures in dependently typed languages.
Figure~\ref{mon-ident} is an example of such a proposition.
\begin{figure}[h]
  \ExecuteMetaData[Monoids.tex]{mon-ident}
  \caption{Example Identity}
  \label{mon-ident}
\end{figure}

To a human, the fact that the identity holds may well be obvious:
\(\AgdaField{∙}\) is associative, so scrub out all the parentheses, and
\(\AgdaField{ε}\) is the identity element, so scrub it out too. After that, both
sides are equal, so voilà!

Unfortunately, to convince the compiler we need to specify every instance of
associativity and identity, rewriting the left-hand-side repeatedly until it
matches the right:
\ExecuteMetaData[Monoids.tex]{mon-proof}

The syntax mimics that of normal, handwritten proofs: the successive ``states''
of the expression are interspersed with equivalence proofs (in the brackets).
Perhaps surprisingly, the syntax is not built-in: it's simply defined in the
standard library.

Despite the powerful syntax, the proof is mechanical, and it's clear that
similar proofs would become tedious with more variables or more complex algebras
(like rings). Luckily, we can automate the procedure.
\subsection{Canonical Forms}
Automation of equality proofs like the one above can be accomplished by first
rewriting both sides of the equation into a canonical form. This form depends on
the particular algebra used in the pair of expressions. For instance, a suitable
canonical form for monoids is lists.
\ExecuteMetaData[Monoids.tex]{list-def}

This type can be thought of as an AST for the ``language of lists''. Crucially,
it's equivalent to the ``language of monoids'': this is the language of
expressions written using only variables and the monoid operations, like the
expressions in figure~\ref{mon-ident}. The neutral element and binary operator
have their equivalents in lists: \(\epsilon\) is simply the empty list, whereas
\(\bullet\) is list concatenation.
\ExecuteMetaData[Monoids.tex]{list-monoid}

We can translate between the language of lists and monoid expressions
\footnote{
  For simplicity's sake, instead of curried functions of \(n\)
  arguments, we'll deal with functions which take a vector of length \(n\), that
  refer to each variable by position, using Fin, the type of finite sets. Of
  course these two representations are equivalent, but the translation is not
  directly relevant to what we're doing here: we refer the interested reader to
  the Relation.Binary.Reflection module of Agda's standard
  library\cite{danielsson_agda_2018}.
}
with \(\AgdaFunction{μ}\) and \(\AgdaFunction{η}\).
\ExecuteMetaData[Monoids.tex]{list-trans}

We have one half of the equality so far: that of the canonical forms. As such,
we have an ``obvious'' proof of the identity in figure~\ref{mon-ident},
expressed in the list language (figure~\ref{list-obvious}).
\begin{figure}[!h]
  \ExecuteMetaData[Monoids.tex]{list-obvious}
  \caption{The identity in figure~\ref{mon-ident}, expressed in the list
    language}
  \label{list-obvious}
\end{figure}
\subsection{Homomorphism}
Figure~\ref{list-obvious} gives us a proof of the form:

\begin{equation}
  \label{list-list}
  \text{lhs}_{list} = \text{rhs}_{list}
\end{equation}

What we want, though, is the following:

\begin{equation}
  \label{mon-mon}
  \text{lhs}_{mon} = \text{rhs}_{mon}
\end{equation}

Equation~\ref{list-list} can be used to build equation~\ref{mon-mon}, if we
supply two extra proofs:

\begin{equation}
  \text{lhs}_{mon} \overset{a}{=} \text{lhs}_{list} = \text{rhs}_{list}
  \overset{b}{=} \text{rhs}_{mon}
\end{equation}

The proofs labeled \(a\) and \(b\) are the task of this section.

First, we'll define a concrete AST for the monoid language
(figure~\ref{mon-ast}). It has constructors for each of the monoid operations
(\(\AgdaInductiveConstructor{⊕}\) and \(\AgdaInductiveConstructor{e}\) are
\(\bullet\) and \(\epsilon\), respectively), and it's indexed by the number of
variables it contains, which are constructed with \(\nu\). Converting back to an
opaque function is accomplished in figure~\ref{eval-ast}.

\begin{figure}
  \ExecuteMetaData[Monoids.tex]{mon-ast}
  \caption{The AST for the Monoid Language}
  \label{mon-ast}
\end{figure}
\begin{figure}
  \ExecuteMetaData[Monoids.tex]{eval-ast}
  \caption{Evaluating the Monoid Language AST}
  \label{eval-ast}
\end{figure}

Finally, then, we must prove the equivalence of the monoid and list languages.
This consists of the following proofs:

\begin{align}
  (\eta x) \mu \rho           &= \left\lsem \nu x \right\rsem \rho      \\
  (x \mdoubleplus y) \mu \rho &= \left\lsem x \oplus y \right\rsem \rho \\
  [] \mu \rho                 &= \left\lsem e \right\rsem \rho
\end{align}
The latter two proofs comprise a monoid homomorphism.

The proofs are constrained: we are only permitted to use the laws provided in
the Monoid record, and the equivalence relation is kept abstract. The fact that
we're not simply using propositional equality allows for some interesting
applications (see section~\ref{setoid-applications}), but it also removes some
familiar tools we may reach for in proofs. Congruence in particular must be
specified explicitly: the combinator \(\AgdaFunction{∙-cong}\) is provided for
this purpose. With this understood, the proofs can be written:
\ExecuteMetaData[Monoids.tex]{correct-ast}
\subsection{Usage}
Combining all of the components above, with some plumbing provided by the
Relation.Binary.Reflection module, we can finally automate the solving of the
original identity in figure~\ref{mon-ident}:
\ExecuteMetaData[Monoids.tex]{ident-auto-proof}
\subsection{Reflection}
One annoyance of the automated solver is that we have to write the expression we
want to solve twice: once in the type signature, and again in the argument
supplied to solve. Agda can infer the type signature:
\ExecuteMetaData[Monoids.tex]{ident-infer-proof}
But we would prefer to write the expression in the type signature, and have it
infer the argument to solve, as the expression in the type signature is the
desired equality, and the argument to solve is something of an implementation
detail.

\todo{Fill in reflection section} This inference can be accomplished using
Agda's reflection mechanisms.
\section{A Polynomial Solver}
We now know the components required for an automatic solver for some algebra: a
canonical form, a concrete representation of expressions, and a proof of
correctness. We now turn our focus to polynomials.

Prior work in this area includes\cite{geuvers_automatically_2017},
\cite{meshveliani_dependent_2013}, \cite{zalakain_evidence-providing_2017},
\cite{cheng_functional_2018}, and \cite{russino_polynomial_2017}, but perhaps
the state-of-the-art (at least in terms of efficiency) is Coq's \texttt{ring}
tactic\cite{the_coq_development_team_2018_1219885}, which is based on an
implementation described in\cite{hutchison_proving_2005}.

That implementation has a number of optimizations which dramatically improve the
complexity of evaluation, but it also includes a careful choice of algebra which
allows for maximum reuse. The choice of algebra has been glossed over thus far,
but it is an important design decision: choose one with too many laws, and the
solver becomes unusable for several types; too few, and we may miss out on
normalization opportunities.

The algebra defined in \cite{hutchison_proving_2005} is that of an
\emph{almost-ring}. This is a ring-like algebra, which discards the requirement
that negation is an inverse (\(x + (-x) = 0\)). Instead, it merely requires that
negation distribute over addiction and multiplication appropriately. This
allows the solver to be used with non-negative types, like \(\mathbb{N}\), where
negation is simply the identity function. Also, because the implementation uses
coefficients in the underlying ring, we lose no opportunities for normalization,
as identities like \(x + (-x) = 0\) will indeed compute.
\section{Horner Normal Form}
The canonical representation of polynomials is a list of coefficients, least
significant first (``Horner Normal Form''). Our initial attempt at encoding this
representation will begin like so:
\ExecuteMetaData[Rings.tex]{dense-opening}

The entire module is parameterized by the choice of coefficient. This
coefficient should support the ring operations, but it is ``raw'', i.e. it
doesn't prove the ring laws. The operations on the polynomial itself are defined
like so\footnote{
  Symbols chosen for operators use the following mnemonic:
  \begin{enumerate}
    \item Operators preceded with ``\(\mathbb{N}.\)'' are defined over
      \(\mathbb{N}\); e.g. \(\mathbb{N}.+\), \(\mathbb{N}.*\).
    \item Plain operators, like \(+\) and \(*\), are defined over the
      coefficients.
    \item Boxed operators, like \(\boxplus\) and \(\boxtimes\), are defined over
      polynomials.
    \item Operators which are boxed on one side are defined over polynomials on
      the corresponding side, and the coefficient on the other; e.g.
      \(\ltimes\), \(\rtimes\).
  \end{enumerate}
}:
\ExecuteMetaData[Rings.tex]{dense-impl}
\subsection{Sparse Horner Normal Form}
As it stands, the above representation has two problems:

\begin{description}
  \item[Redundancy] The representation suffers from the problem of trailing
    zeroes. In other words, the polynomial $2x$ could be represented by any of
    the following:
  
    \begin{align*}
      & 0, 2 \\
      & 0, 2, 0 \\
      & 0, 2, 0, 0 \\
      & 0, 2, 0, 0, 0, 0, 0
    \end{align*}
    
    This is a problem for a solver: the whole \emph{point} is that equivalent
    expressions are represented the same way.

  \item[Inefficiency] Expressions will tend to have large gaps, full only of
    zeroes. Something like $x^5$ will be represented as a list with 6 elements,
    only the last one being of interest. Since addition is linear in the length
    of the list, and multiplication quadratic, this is a major concern.
\end{description}

In\cite{hutchison_proving_2005}, the problem is addressed primarily from the
efficiency perspective: they add a field for the ``power index''. For our case,
we'll just store a list of pairs, where the second element of the pair is the
power index\footnote{
  In\cite{hutchison_proving_2005}, the expression \((c , i) \squaredots P\)
  represents \(P \times X^i + c\). We found that \(X^i \times (c + X \times P)\)
  is a more natural translation, and it's what we use here. A power index of
  \(i\) in this representation is equivalent to a power index of \(i+1\)
  in\cite{hutchison_proving_2005}.
}.

As an example, the polynomial:
\[ 3 + 2x^2 + 4x^5 + 2x^7 \]
Will be represented as:
\[ (3,0),(2,1),(4,2),(2,1) \]
Or, mathematically:
\[ x^0 (3 + x x^1 (2 + x x^2 * (4 + x x^1 (2 + x 0)))) \]
\subsubsection{Uniqueness}
While this form solves our efficiency problem, we still have redundant
representations of the same polynomials. In\cite{hutchison_proving_2005}, care
is taken to ensure all operations include a normalizing step, but this is not
verified: in other words, it is not proven that the polynomials are always in
normal form.

Expressing that a polynomial is in normal form turns out to be as simple as
disallowing zeroes: without them, there can be no trailing zeroes, and all gaps
must be represented by power indices. To check for zero, we require the user
supply a decidable predicate on the coefficients. This changes the module
declaration like so:
\ExecuteMetaData[Rings.tex]{sparse-opening}

Finally, we can define a sparse encoding of Horner Normal Form:
\ExecuteMetaData[Rings.tex]{sparse-decl}

The proof of nonzero is marked irrelevant (preceded with a dot) to avoid
computing it at runtime.

We can wrap up the implementation with a cleaner interface by providing a
normalizing version of \(\squaredots\):
\ExecuteMetaData[Rings.tex]{sparse-norm}
\subsubsection{Comparison}
Our addition and multiplication functions will need to properly deal with the
new gapless formulation. First things first, we'll need a way to match the power
indices. We can use a function from\cite{mcbride_view_2004} to do so.
\ExecuteMetaData[Rings.tex]{compare}
This is a classic example of a ``leftist'' function: after pattern matching on
one of the constructors of \(\AgdaDatatype{Ordering}\), it gives you information
on type variables to the \emph{left} of the pattern. In other words, when you
run the function on some variables, the result of the function will give you
information on its arguments.
\subsubsection{Efficiency}
The implementation of \(\AgdaFunction{compare}\) may raise suspicion with
regards to efficiency: if this encoding of polynomials improves time complexity
by skipping the gaps, don't we lose all of that when we encode the gaps as Peano
numbers?

The answer is a tentative no. Firstly, since we are comparing gaps, the
complexity can be no larger than that of the dense implementation. Secondly, the
operations we're most concerned about are those on the underlying coefficient;
and, indeed, this sparse encoding does reduce the number of those significantly.
Thirdly, if a fast implementation of \(\AgdaFunction{compare}\) is really and
truly demanded, there are tricks we can employ.

Agda has a number of built-in functions on the natural numbers: when applied to
closed terms, these call to an implementation on Haskell's \texttt{Integer}
type, rather than the unary implementation. For our uses, the functions of
interest are \(\AgdaFunction{-}\), \(\AgdaFunction{+}\), \(\AgdaFunction{<}\),
and \(\AgdaFunction{==}\). The comparison functions provide booleans rather than
evidence, but we can prove they correspond to the evidence-providing versions.
Combined with judicious use of \(\AgdaFunction{erase}\), we get the following:
\ExecuteMetaData[Rings.tex]{unsafe-compare}
\subsubsection{Termination}
Unfortunately, we cannot yet define addition and multiplication. Using
\(\AgdaFunction{compare}\) above in the most obvious way won't pass the
termination checker.
\ExecuteMetaData[Rings.tex]{nonterminating-addition}

Agda needs to be able to see that one of the numbers returned by
\(\AgdaFunction{compare}\) always reduces in size: however, since the difference
is immediately packed up in a list in the recursive call, it's buried too deeply
in constructors for the termination checker to see it.

The solution is twofold: unpack any constructors into function arguments as soon
as possible, and eliminate any redundant pattern matches in the offending
functions. Taken together, these form an optimization known as ``call pattern
specialization''\cite{jones_call-pattern_2007}: it's performed automatically in
GHC, here we're doing it manually. Perhaps a similar transformation could be
automatically applied before termination checking in Agda's compiler.

Until then, the structurally terminating function is defined like so:
\ExecuteMetaData[Rings.tex]{addition}
Ever helper function in the mutual block matches on exactly one argument,
eliminating redundancy. Happily, this makes the function more efficient, as well
as more obviously terminating.
\section{Binary}
Before continuing with polynomials, we'll take a short detour to look at binary
numbers. These have a number of uses in dependently typed programming: as well
as being a more efficient alternative to Peano numbers, their structure informs
that of many data structures, such as binomial heaps, and as such they're used
in proofs about those structures.

Similarly to polynomials, though, the naïve representation suffers from
redundancy in the form of trailing zeroes. There are a number of ways to
overcome this (see\cite{meshveliani_binary-4_2018}
and\cite{escardo_libraries_2018}, for example); yet another is the repurposing
of our sparse polynomial from above.
\ExecuteMetaData[Binary.tex]{binary-def}
We don't need to store any coefficients, because 1 is the only permitted
coefficient. Effectively, all we store is the distance to another 1.

Addition (elided here for brevity) is linear in the number of bits, as expected,
and multiplication takes full advantage of the sparse representation:
\ExecuteMetaData[Binary.tex]{binary-mul}
\section{Multivariate}
Up until now our polynomial has been an expression in just one variable. For it
to be truly useful, though, we'd like to be able to extend it to many: luckily
there's a well-known isomorphism we can use to extend our earlier
implementation. A multivariate polynomial is one where its coefficients are
polynomials with one fewer variable\cite{cheng_functional_2018}.

Before going any further, though, we should notice that this type is dense with
regards to nesting the same way that the original monomial type was dense with
regards to exponentiation. Every polynomial with \(n\) variables will be
represented by \(n\) nested polynomials, regardless of how many of the variables
in the expression are non-constant.
\subsection{Sparse Nesting}
It's immediately clear that removing the gaps from the nesting will be more
difficult than it was for the exponents: the \(\AgdaDatatype{Poly}\) type is
\emph{indexed} by the number of variables it contains, so any manipulation of
that number will have to carefully prove its correctness.

Our first approach might mimic the structure of \(\AgdaDatatype{Ordering}\),
with an indexed type:
\ExecuteMetaData[Poly.tex]{poly-slime}
Where \(\AgdaDatatype{FlatPoly}\) is effectively the gappy type we had earlier.
If you actually tried to use this type, though, you'd run into issues. Pattern
matching on a pair of \(\AgdaDatatype{Poly}\)s won't work, as Agda cannot
(usually) unify user-defined functions. How do we avoid this? ``Don't touch the
green slime!''\cite{mcbride_polynomial_2018}:
\begin{displayquote}
  When combining prescriptive and descriptive indices, ensure both are in
  constructor form. Exclude defined functions which yield difficult unification
  problems.
\end{displayquote}
We'll have to take another route.
\subsubsection{Inequalities}
First, we'll define our polynomial like so:
\ExecuteMetaData[Poly.tex]{poly}
The gap is now implicit; instead, we store a proof that the nested polynomial
has no more variables then the outer. Next, the rest of the types are similar to
what they were before:
\ExecuteMetaData[Poly.tex]{poly-types}
New here is the \(\AgdaFunction{Norm}\) function, in
\(\AgdaDatatype{FlatPoly}\). Like \(\AgdaFunction{Zero}\) in
\(\AgdaDatatype{Coeff}\), it proves that there really are no gaps (here in the
nesting, rather then exponentiation, though). Its definition is as follows:
\ExecuteMetaData[Poly.tex]{poly-norm}
Again, similarly to the sparse exponent encoding, we provide a smart
constructor which ensures normalization.
\subsubsection{Choosing an Inequality}
Conspicuously missing above is a definition for \(\leq\).
\begin{description}
  \item[Option 1: The Standard Way] The most commonly used definition of
    \(\leq\) is as follows:
    \ExecuteMetaData[Poly.tex]{leq-1}
    For our purposes, though, this type is dangerous: it actually
    \emph{increases} the complexity from the dense encoding. To understand why,
    remember the addition function above with the gapless exponent encoding. For
    it to work, we needed to compare the gaps, and proceed based on that. We'll
    need to do a similar comparison on variable counts for this gapless
    encoding. However, we don't store the \emph{gaps} now, we store the number
    of variables in the nested polynomial. Consider the following sequence of
    nestings:

    \[ (5 ≤ 6), (4 ≤ 5), (3 ≤ 4), (1 ≤ 3), (0 ≤ 1) \]

    The outer polynomial has 6 variables, but it has a gap to its inner
    polynomial of 5, and so on. The comparisons will be made on 5, 4, 3, 1, and
    0. Like repeatedly taking the length of the tail of a list, this is
    quadratic. There must be a better way.


  \item[Option 2: With Propositional Equality] Once you realize we need to be
    comparing the gaps and not the tails, another encoding of \(\leq\) in
    Data.Nat seems the best option:
    \ExecuteMetaData[Poly.tex]{leq-2}
    It stores the gap \emph{right there}: in \(k\)!

    Unfortunately, though, we're still stuck. While you can indeed run your
    comparison on \(k\), you're not left with much information about the rest.
    Say, for instance, you find out that two respective \(k\)s are equal. What
    about the \(m\)s? Of course, you \emph{can} show that they must be equal as
    well, but it requires a proof. Similarly in the less-than or greater-than
    cases: each time, you need to show that the information about \(k\)
    corresponds to information about \(m\). Again, all of this can be done, but
    it all requires propositional proofs, which are messy, and slow. Erasure is
    an option, but I'm not sure of the correctness of that approach.
  \item[Option 3] What we really want is to \emph{run} the comparison function
    on the gap, but get the result on the tail. Turns out we can do exactly that
    with the following:
    \ExecuteMetaData[Poly.tex]{leq-3}
    While this structure stores the inequality by induction on the gap. That
    structure can be used to write a comparison function which was linear in the
    size of the gap (even though it compares the length of the tail).
    \todo{Explain more the path from this to the final version. Intermediate
      comparison function and axiom K, especially}

\end{description}
\subsubsection{Indexed Ordering}
Now that the inequality is an inductive type, which mimics a Peano number stored
in the gap, the parallels with the sparse exponent encoding should be even more
clear. To write a comparison function, then, we should first look for an
equivalent to addition. This turns out to be transitivity:
\ExecuteMetaData[Poly.tex]{trans}

With this defined, the \(\AgdaDatatype{Ordering}\) type is obvious:
\ExecuteMetaData[Poly.tex]{ind-ordering}

\section{Writing The Proofs}
The proofs are long (roughly 1000 lines), albeit mechanical.
\subsection{Equational Reasoning Techniques}
\todo{Expand on the proofs. Operators used, etc.}
\subsection{The Algebra of Programming and List Homomorphisms}
\todo{
  I haven't actually been able to apply the ``algebra of
  programming''\cite{mu_algebra_2009} stuff in the proofs themselves yet. This
  section may well be removed if it turns out I can't manage it, but for now it
  seems like a promising avenue that might get us some cleaner, more interesting
  proofs. Especially since so many of the functions are written as folds on
  lists.
}
\section{Setoid Applications} \label{setoid-applications}
I mentioned that the notion of equality we were using was more general than
propositional, and that we could use it more flexibly in different contexts.
\subsection{Traced}
One ``equivalence relation'' is simply a labeled path: a list of rewrite rules
or identities, repeatedly applied until the left-hand-side has been changed to
the right. Print out the labels when done, and you have a step-by-step computer
algebra system à la Wolfram Alpha. The definition of this type is
straightforward:
\ExecuteMetaData[Setoids.tex]{trace-def}
And it does indeed implement the expected properties of an equivalence relation:
\ExecuteMetaData[Setoids.tex]{trace-impl}
\todo{Expand on the traced version, maybe clean it up? Also provide some
  examples.}
\subsection{Isomorphisms}
\todo{Use the proof to translate between types. Check out Conor McBride's work
  on containers for this.}
\subsection{Counterexamples}
\todo{Possible to provide counterexamples if a proof fails?}
\section{The Correct-by-Construction Approach}
Correct-by-construction is another approach\cite{geuvers_automatically_2017}.
\ExecuteMetaData[Constr.tex]{constr-def}
\begin{figure*}[!h]
  \ExecuteMetaData[Constr.tex]{constr-add}
\end{figure*}
\bibliographystyle{IEEEtranS}
\bibliography{horners-rule.bib}
\end{document}